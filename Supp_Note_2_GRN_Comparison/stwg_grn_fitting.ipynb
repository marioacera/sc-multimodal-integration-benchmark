{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d9b39e-d1de-460a-8abb-bc997cf368d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 16:28:58.631036: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-08 16:28:58.646811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-08 16:28:58.665659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-08 16:28:58.671400: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-08 16:28:58.685628: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-08 16:28:59.575037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "@contextmanager\n",
    "def ignore_warnings():\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        yield\n",
    "\n",
    "from numba.core.errors import NumbaDeprecationWarning\n",
    "warnings.filterwarnings('ignore', category=NumbaDeprecationWarning)\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import mudata as md\n",
    "import muon as mu\n",
    "import pyranges as pr\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b6b87a-027d-4602-b5c9-ef68656d287d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW_MDATA_PATH=../data/stwg-v2.h5mu\n",
      "MDATA_PATH=../data/stwg-v2-filtered.h5mu\n",
      "OUTPUT_DIR=../analysis/\n",
      "JASPAR_PATH=../data/JASPAR2024_CORE_vertebrates_non-redundant_pfms_jaspar.txt\n",
      "REFTSS_PATH=../data/reftss.pkl\n",
      "HPA_PATH=../data/hpa_tfs.pkl\n",
      "CHIPATLAS_PATH=../data/chipatlas_kidney_promoters.pkl\n",
      "PLATFORM=batch\n",
      "SAMPLE=sample\n",
      "CELLTYPE=celltype\n",
      "GEX=rna\n",
      "ACC=atac\n",
      "MIN_CELLS=30\n",
      "PROXIMAL_BP=5000\n",
      "RANDOM_STATE=0\n",
      "NORMALIZE_TOTAL=False\n",
      "NUM_CELLS=None\n",
      "READS_PER_CELL=None\n",
      "NUM_TOP_GENES=1000\n",
      "MIN_SAMPLES=-1\n",
      "NUM_TREES=20\n",
      "LEARNING_RATE=0.5\n",
      "MAX_DEPTH=None\n",
      "EARLY_STOPPING=3\n",
      "FEATURE_FRACTION=1\n",
      "BAGGING_FRACTION=1\n",
      "LEAVE_P_OUT=2\n",
      "IMPORTANCE_THRESHOLD=0.95\n",
      "CORRELATION_THRESHOLD=0.2\n"
     ]
    }
   ],
   "source": [
    "from stwg_grn_params import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da445254-6c66-4abd-a36f-34e2c376eb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gridsan/mmurphy/.local/lib/python3.10/site-packages/mudata/_core/mudata.py:1531: FutureWarning: From 0.4 .update() will not pull obs/var columns from individual modalities by default anymore. Set mudata.set_options(pull_on_update=False) to adopt the new behaviour, which will become the default. Use new pull_obs/pull_var and push_obs/push_var methods for more flexibility.\n",
      "  self._update_attr(\"var\", axis=0, join_common=join_common)\n",
      "/home/gridsan/mmurphy/.local/lib/python3.10/site-packages/mudata/_core/mudata.py:1429: FutureWarning: From 0.4 .update() will not pull obs/var columns from individual modalities by default anymore. Set mudata.set_options(pull_on_update=False) to adopt the new behaviour, which will become the default. Use new pull_obs/pull_var and push_obs/push_var methods for more flexibility.\n",
      "  self._update_attr(\"obs\", axis=1, join_common=join_common)\n"
     ]
    }
   ],
   "source": [
    "mdata = mu.read('../data/stwg-v2-filtered.h5mu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "854f41e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20187"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map genes to proximal regulatory loci\n",
    "\n",
    "from collections import defaultdict\n",
    "pr_acc = mdata.var.reset_index()[['index','atac:Chromosome','atac:Start','atac:End']].dropna()\n",
    "pr_acc.columns = [ACC,'Chromosome','Start','End']\n",
    "pr_acc = pr.PyRanges(pr_acc.drop_duplicates())\n",
    "\n",
    "pr_gex = mdata.var.reset_index()[['index','rna:seqname','rna:start','rna:end']].dropna()\n",
    "pr_gex.columns = [GEX,'Chromosome','Start','End']\n",
    "pr_gex = pr_gex.rename(columns={'Gene_symbol':GEX})\n",
    "pr_gex = pr.PyRanges(pr_gex.drop_duplicates())\n",
    "\n",
    "with ignore_warnings():\n",
    "    gex2acc = pr_gex.join(pr_acc, slack=PROXIMAL_BP).df.groupby(GEX,observed=True)[ACC].agg(set)\n",
    "\n",
    "gex2acc = defaultdict(list, gex2acc.apply(list))\n",
    "\n",
    "len(gex2acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dee8358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "755"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = !grep -oP '^>MA\\d+\\.\\d+\\t(.*)$' {JASPAR_PATH} | cut -f2\n",
    "tfs = set('::'.join(tfs).upper().split('::'))\n",
    "len(tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b517336-7a34-4917-a5c4-bb14abb6152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(gex, acc, obs):\n",
    "    if len(gex) > 0 and len(acc) > 0:\n",
    "        cells = list(set(gex.obs_names)&set(acc.obs_names))\n",
    "        gex = gex[cells]\n",
    "        acc = acc[cells]\n",
    "        obs = obs.loc[cells]\n",
    "\n",
    "    gex = gex.copy()\n",
    "    acc = acc.copy()\n",
    "    obs = obs.copy()\n",
    "    \n",
    "    if READS_PER_CELL:\n",
    "        sc.pp.downsample_counts(gex, total_counts=READS_PER_CELL*len(gex))\n",
    "\n",
    "    obs['total_counts'] = gex.X.sum(1)\n",
    "\n",
    "    sc.pp.filter_genes(gex, min_cells=MIN_CELLS)\n",
    "    sc.pp.filter_genes(acc, min_cells=MIN_CELLS)\n",
    "\n",
    "    if gex.shape[1] > 0:\n",
    "        if NORMALIZE_TOTAL:\n",
    "            sc.pp.normalize_total(gex)\n",
    "        sc.pp.log1p(gex)\n",
    "        with ignore_warnings():\n",
    "            sc.pp.highly_variable_genes(gex, batch_key=SAMPLE, n_top_genes=NUM_TOP_GENES)\n",
    "\n",
    "    num_samples = obs[SAMPLE].nunique()\n",
    "    hvgs = gex.var_names[gex.var.highly_variable_nbatches == num_samples].tolist()\n",
    "\n",
    "    if acc.shape[1] > 0:\n",
    "        acc.X[:] = acc.X > 0\n",
    "\n",
    "    return gex, acc, obs, hvgs\n",
    "\n",
    "def prepare_gbm_data(gene, gex, acc, *, tfs, gex2acc):\n",
    "    X_tfs = gex[:,gex.var_names.isin(tfs) & (gex.var_names != gene)].to_df() # all TFs\n",
    "\n",
    "    X_acc = acc[:,acc.var_names.isin(gex2acc[gene])].to_df() # proximal loci not annotated as this gene's promoter\n",
    "\n",
    "    X = pd.concat([X_tfs, X_acc], axis=1)\n",
    "    X = X.loc[:,X.std(0) > 0]\n",
    "    y = gex[:,gene].to_df().squeeze()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def fit_gbm(X_train, y_train, X_val, y_val):\n",
    "    model = LGBMRegressor(\n",
    "        random_state=RANDOM_STATE, \n",
    "        # force_col_wise=True, \n",
    "        verbose=-1, \n",
    "        importance_type='gain', # split\n",
    "        max_depth=MAX_DEPTH,\n",
    "        n_estimators=NUM_TREES,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        feature_fraction=FEATURE_FRACTION,\n",
    "        bagging_freq=int(BAGGING_FRACTION < 1),\n",
    "        bagging_fraction=BAGGING_FRACTION,\n",
    "        callbacks=[lgb.early_stopping(EARLY_STOPPING)] if EARLY_STOPPING else None\n",
    "    )\n",
    "\n",
    "    model.fit(X_train.values, y_train.values, eval_set=(X_val.values, y_val.values))\n",
    "\n",
    "    importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "\n",
    "    return model, importances\n",
    "\n",
    "def cv_fit_predict_gbm(X, y, obs):\n",
    "    groups = obs[SAMPLE]\n",
    "\n",
    "    leave_p_out = LEAVE_P_OUT if LEAVE_P_OUT > 0 else groups.nunique() + LEAVE_P_OUT\n",
    "    cv = LeavePGroupsOut(leave_p_out)\n",
    "\n",
    "    # y_pred = pd.Series(index=y.index, dtype=float)\n",
    "\n",
    "    y_pred = {}\n",
    "    importances = {}\n",
    "\n",
    "    for train_index, test_index in cv.split(X, y, groups=groups):\n",
    "        split = (tuple(sorted(set(groups.iloc[train_index]))), \n",
    "                 tuple(sorted(set(groups.iloc[test_index]))))\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        model, importances[split] = fit_gbm(X_train, y_train, X_test, y_test)\n",
    "\n",
    "        y_pred[split] = pd.Series(model.predict(X), index=y.index)\n",
    "\n",
    "    # importances = aggregate_feature_importances(importances)\n",
    "    y_pred = pd.DataFrame(y_pred)\n",
    "    y_pred.columns.names = ['train','test']\n",
    "    importances = pd.DataFrame(importances)\n",
    "    importances.columns.names = ['train','test']\n",
    "\n",
    "    return y_pred, importances\n",
    "\n",
    "def get_scores_per_celltype(y, y_pred, obs):\n",
    "    scores = {}\n",
    "    for train, test in y_pred.columns:\n",
    "        for c, _obs in obs.groupby(CELLTYPE,observed=True):\n",
    "            for _test in test:\n",
    "                __obs = _obs[_obs[SAMPLE] == _test]\n",
    "                _y = y.loc[__obs.index]\n",
    "                _y_pred = y_pred.loc[__obs.index, (train,test)].squeeze()\n",
    "                if _y.std() == 0 or _y_pred.std() == 0:\n",
    "                    continue\n",
    "                scores[(train,_test,c)] = _y.corr(_y_pred)\n",
    "    return pd.Series(scores)\n",
    "\n",
    "def fit_gene_model(gene, gex, acc, obs, *, tfs, gex2acc):\n",
    "    X, y = prepare_gbm_data(gene, gex, acc, tfs=tfs, gex2acc=gex2acc)\n",
    "    y_pred, importances = cv_fit_predict_gbm(X, y, obs)\n",
    "    scores = get_scores_per_celltype(y, y_pred, obs)\n",
    "    return scores, importances\n",
    "\n",
    "def xcorr(X, Y):\n",
    "    # Standardize X and Y - note gex is already logged here\n",
    "    X_std = (X - X.mean(0)) / X.std(0)\n",
    "    Y_std = (Y - Y.mean(0)) / Y.std(0)\n",
    "    \n",
    "    # Compute the number of observations\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # Compute the cross-correlation matrix\n",
    "    cross_corr_matrix = np.dot(X_std.T, Y_std) / n\n",
    "    \n",
    "    return cross_corr_matrix\n",
    "\n",
    "def compute_celltype_correlations(gex, obs, *, tfs, hvgs):\n",
    "    C = {}\n",
    "    genes = set(gex.var_names)\n",
    "    tfs = list(tfs&genes)\n",
    "    hvgs = list(hvgs)\n",
    "    for c, _obs in obs[[CELLTYPE]].groupby(CELLTYPE,observed=True):\n",
    "        _X = gex[_obs.index,tfs].to_df()\n",
    "        _Y = gex[_obs.index,hvgs].to_df()\n",
    "        _X = _X.loc[:,_X.std(0)>0]\n",
    "        _Y = _Y.loc[:,_Y.std(0)>0]\n",
    "        _C = pd.DataFrame(xcorr(_X,_Y),index=_X.columns,columns=_Y.columns)\n",
    "        _C = _C.melt(ignore_index=False).reset_index()\n",
    "        _C.columns = ['tf','target','rho']\n",
    "        C[c] = _C.set_index(['tf','target'])['rho']\n",
    "    C = pd.concat(C,axis=1).fillna(0)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eced24e1-2ac7-4a9c-a329-352bffc245d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from tqdm import tqdm\n",
    "\n",
    "grns = {}\n",
    "celltype_scores = {}\n",
    "\n",
    "for platform, obs in mdata.obs.groupby(PLATFORM,observed=True):\n",
    "    print(platform)\n",
    "    \n",
    "    _mdata = mdata[obs.index]\n",
    "\n",
    "    gex, acc, obs, hvgs = preprocess_data(_mdata[GEX], _mdata[ACC], _mdata.obs)\n",
    "\n",
    "    _celltype_scores = {}\n",
    "    importances = {}\n",
    "\n",
    "    for gene in tqdm(hvgs):\n",
    "        _celltype_scores[gene], _importances = fit_gene_model(\n",
    "            gene,\n",
    "            gex, acc, obs,\n",
    "            tfs=tfs, gex2acc=gex2acc\n",
    "        )\n",
    "        _importances = _importances[_importances.index.isin(tfs)]\n",
    "        importances[gene] = _importances\n",
    "        \n",
    "    celltype_scores[platform] = pd.DataFrame(_celltype_scores)\n",
    "    importances = pd.concat(importances).rank(axis=0,pct=True,method='dense')\n",
    "    importances.index.names = ['target','tf']\n",
    "        \n",
    "    celltype_corrs = []\n",
    "    for train, test in importances.columns:\n",
    "        _obs = obs[obs[SAMPLE].isin(train)]\n",
    "        _celltype_corrs = compute_celltype_correlations(\n",
    "            gex[_obs.index], _obs, tfs=tfs, hvgs=hvgs\n",
    "        )\n",
    "        _celltype_corrs['train'] = [train] * len(_celltype_corrs)\n",
    "        celltype_corrs.append(_celltype_corrs)\n",
    "    celltype_corrs = pd.concat(celltype_corrs)\n",
    "    celltype_corrs = celltype_corrs.reset_index().set_index(['train','target','tf'])\n",
    "    \n",
    "    _grns = (\n",
    "        importances.melt(ignore_index=False)\n",
    "        .reset_index()\n",
    "        .set_index(['train','tf','target'])\n",
    "        .drop(columns='test')\n",
    "    )\n",
    "    _grns = _grns[_grns['value']>=IMPORTANCE_THRESHOLD][[]]\n",
    "    _grns = _grns.join(celltype_corrs,how='inner')\n",
    "    grns[platform] = _grns\n",
    "\n",
    "celltype_scores = pd.concat(celltype_scores)\n",
    "celltype_scores.index.names = [PLATFORM, 'train', 'test', CELLTYPE]\n",
    "celltype_scores.to_pickle(f'{OUTPUT_DIR}/scores.pickle')\n",
    "    \n",
    "grns = pd.concat(grns)\n",
    "grns.index.names = [PLATFORM, *grns.index.names[1:]]\n",
    "grns.to_pickle(f'{OUTPUT_DIR}/grns.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
