{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643b9c9-3ec3-4af3-a083-c5b51c066612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 16:01:28.062424: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 16:01:28.215952: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 16:01:28.216960: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['pdf.fonttype'] = 42 # enables correct plotting of text\n",
    "rcParams['figure.figsize'] = (7,7)\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 42\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "# Import deepscore model # Add deepscore folder to path\n",
    "from deepscore import deepscore \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b84a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LOAD the PROCESS the REFERENCE\n",
    "\n",
    "# ## Preprocessing\n",
    "\n",
    "\n",
    "cell_type = 'subclass.l1'\n",
    "\n",
    "ref_py = sc.read('/home/macera/Documentos/CZI/MANUSCRIPT_PREP/HORIZONTAL_RNA/objects/local.h5ad')  # LOAD the HCA Atlas\n",
    "ref_py = ref_py.raw.to_adata()\n",
    "ref_py.layers['counts'] = ref_py.X.copy()\n",
    "\n",
    "ref_py.var['ENSG'] = ref_py.var.index.copy()\n",
    "ref_py.var.index = ref_py.var['feature_name'].copy()\n",
    "\n",
    "# SUBSET THE ATLAS TO MATCH OUR SAMPLE BIOLOGY\n",
    "\n",
    "cortex_celltypes_l1= ['DCT',\n",
    " 'PEC',\n",
    " 'CNT',\n",
    " 'POD',\n",
    " 'PT',\n",
    " 'IC',\n",
    " 'IMM',\n",
    " 'NEU',\n",
    " 'VSM/P',\n",
    " 'TAL',\n",
    " 'EC',\n",
    " 'FIB',\n",
    " 'PC']\n",
    "\n",
    "cortex_celltypes_l3= ['DCT1',\n",
    " 'DCT2',\n",
    " 'IC-B',\n",
    " 'B',\n",
    " 'MD',\n",
    " 'CNT-IC-A',\n",
    " 'MC',\n",
    " 'CNT',\n",
    " 'PT-S1/2',\n",
    " 'CCD-IC-A',\n",
    " 'PEC',\n",
    " 'pDC',\n",
    " 'EC-GC',\n",
    " 'POD',\n",
    " 'VSMC',\n",
    " 'aPT',\n",
    " 'CNT-PC',\n",
    " 'FIB',\n",
    " 'cDC',\n",
    " 'REN',\n",
    " 'EC-PTC',\n",
    " 'T',\n",
    " 'PT-S3',\n",
    " 'ncMON',\n",
    " 'NKC/T',\n",
    " 'aTAL1',\n",
    " 'C-TAL',\n",
    " 'PL',\n",
    " 'CCD-PC',\n",
    " 'SC/NEU',\n",
    " 'EC-LYM',\n",
    " 'MDC',\n",
    " 'N',\n",
    " 'MAST',\n",
    " 'aTAL2',\n",
    " 'aFIB',\n",
    " 'MYOF',\n",
    " 'MAC-M2',\n",
    " 'EC-AEA',\n",
    " 'VSMC/P']\n",
    "\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['subclass.l1'].isin(cortex_celltypes_l1)]\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['subclass.l3'].isin(cortex_celltypes_l3)]\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['condition.long'].isin(['Normal Reference'])]\n",
    "\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['state.l2'].isin(['reference','adaptive - epi','adaptive - str'])].copy()\n",
    "\n",
    "\n",
    "cell_type = 'subclass.l1'\n",
    "overlapping = False\n",
    "compute = False\n",
    "\n",
    "\n",
    "ref_py.X = ref_py.X.copy()\n",
    "sc.pp.normalize_total(ref_py, target_sum=1e4)\n",
    "sc.pp.log1p(ref_py)\n",
    "\n",
    "\n",
    "markers_filename= f'HCA_l1'\n",
    "\n",
    "# Identify HCA ATLAS differentially expressed genes between cell types \n",
    "\n",
    "if compute == True:\n",
    "    sc.tl.rank_genes_groups(ref_py, cell_type, method='wilcoxon', use_raw=False)\n",
    "    ranked_genes_populations = ref_py.uns['rank_genes_groups'].copy()\n",
    "    with open(f'/home/macera/Documentos/CZI/MANUSCRIPT_PREP/DEEPSCORE/markers_ds/{markers_filename}.pickle', 'wb') as handle:\n",
    "        pickle.dump(ranked_genes_populations, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(f'/home/macera/Documentos/CZI/MANUSCRIPT_PREP/DEEPSCORE/markers_ds/{markers_filename}.pickle', 'rb') as handle:\n",
    "        ranked_genes_populations = pickle.load(handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36502a-1d96-4280-aca7-c73380a1e9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b46d0-4c2d-4c90-859f-d69e3c38dcd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "## SET PARAMETERS\n",
    "n_markers = 500 # Max number of markers to use per cell-type\n",
    "overlapping = False # Parameter to control overlapping marker genes between cell types on the prediction.\n",
    "\n",
    "\n",
    "ref_py_save = ref_py.copy()\n",
    "mod = 'RECK'\n",
    "if os.path.exists(f'csv/Deepscore_HCA_l1_{mod}_CLEAN.csv'):\n",
    "    print(f'{mod} already exists!')\n",
    "\n",
    "adata = sc.read(f'/home/macera/Documentos/CZI/MANUSCRIPT_PREP/REVIEWS/external_data/reck/rna_ready.h5ad', compression='gzip')\n",
    "# adata = adata.raw.to_adata()\n",
    "adata.layers['counts'] = adata.X.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82757764-83d3-4912-a5e4-464ba49eec5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 2550)              10200     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense1024 (Dense)           (None, 1024)              2612224   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1024)              4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " output (Dense)              (None, 13)                3341      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2893285 (11.04 MB)\n",
      "Trainable params: 2885625 (11.01 MB)\n",
      "Non-trainable params: 7660 (29.92 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 15:44:37.757842: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 584194800 exceeds 10% of free system memory.\n",
      "2025-09-02 15:44:38.191204: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 525769200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "403/403 [==============================] - 15s 34ms/step - loss: 0.1792 - categorical_accuracy: 0.9458 - val_loss: 0.1151 - val_categorical_accuracy: 0.9619 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "403/403 [==============================] - 13s 32ms/step - loss: 0.0459 - categorical_accuracy: 0.9846 - val_loss: 0.1220 - val_categorical_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "403/403 [==============================] - 13s 33ms/step - loss: 0.0266 - categorical_accuracy: 0.9910 - val_loss: 0.1531 - val_categorical_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "403/403 [==============================] - 13s 32ms/step - loss: 0.0200 - categorical_accuracy: 0.9932 - val_loss: 0.1529 - val_categorical_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "403/403 [==============================] - 12s 30ms/step - loss: 0.0172 - categorical_accuracy: 0.9942 - val_loss: 0.1607 - val_categorical_accuracy: 0.9619 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "403/403 [==============================] - 13s 32ms/step - loss: 0.0184 - categorical_accuracy: 0.9939 - val_loss: 0.1760 - val_categorical_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "403/403 [==============================] - 12s 30ms/step - loss: 0.0140 - categorical_accuracy: 0.9952 - val_loss: 0.1867 - val_categorical_accuracy: 0.9612 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "403/403 [==============================] - 13s 32ms/step - loss: 0.0129 - categorical_accuracy: 0.9957 - val_loss: 0.1826 - val_categorical_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "403/403 [==============================] - 12s 30ms/step - loss: 0.0122 - categorical_accuracy: 0.9958 - val_loss: 0.1792 - val_categorical_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "403/403 [==============================] - 12s 30ms/step - loss: 0.0176 - categorical_accuracy: 0.9940 - val_loss: 0.1938 - val_categorical_accuracy: 0.9581 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "403/403 [==============================] - 12s 30ms/step - loss: 0.0164 - categorical_accuracy: 0.9942 - val_loss: 0.1856 - val_categorical_accuracy: 0.9591 - lr: 9.0484e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.2197 - categorical_accuracy: 0.9569\n",
      "\n",
      "test loss: 0.21975, test accuracy:'               '0.95695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 15:46:59.583749: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 478961400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/367 [>.............................] - ETA: 1s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 15:46:59.845977: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 478961400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367/367 [==============================] - 4s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "with open(f'markers_ds/{markers_filename}.pickle', 'rb') as handle:\n",
    "    ranked_genes_populations = pickle.load(handle) \n",
    "\n",
    "if overlapping:\n",
    "    selected_markers =[]\n",
    "    for cell_type_ in ref_py.obs[cell_type].unique():\n",
    "        cell_type_markers = []\n",
    "        for marker in ranked_genes_populations['names'][cell_type_][:n_markers]:\n",
    "            if marker in adata.var.index: \n",
    "                selected_markers.append(marker)\n",
    "    selected_markers = set(selected_markers)\n",
    "\n",
    "else:\n",
    "    # Step 2: Store markers for each subset\n",
    "    subset_markers_dict ={}\n",
    "    for subset in ref_py.obs[cell_type].unique():\n",
    "        subset_markers = ranked_genes_populations['names'][subset]\n",
    "        subset_markers = [gene for gene in subset_markers if gene in adata.var.index]\n",
    "        subset_markers_dict[subset] = set(subset_markers[:n_markers+100])\n",
    "\n",
    "    # Step 3: Identify overlapping markers\n",
    "    overlapping_markers = set()\n",
    "    for subset, markers in subset_markers_dict.items():\n",
    "        for other_subset, other_markers in subset_markers_dict.items():\n",
    "            if subset != other_subset:\n",
    "                overlapping_markers.update(markers.intersection(other_markers))\n",
    "\n",
    "    # Step 4: Select markers for each subset, excluding overlapping markers\n",
    "    marker_dict = {}\n",
    "    for subset, markers in subset_markers_dict.items():\n",
    "        unique_markers = [marker for marker in markers if marker not in overlapping_markers]\n",
    "        marker_dict[subset] = unique_markers[:n_markers]  # Select up to TOP n_markers\n",
    "    selected_markers = [marker for subset in marker_dict for marker in marker_dict[subset]]\n",
    "\n",
    "\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "\n",
    "# Subset the data to the selected markers\n",
    "\n",
    "ref_py = ref_py_save[:, list(selected_markers)].copy()\n",
    "adata = adata[:, list(selected_markers)].copy()\n",
    "\n",
    "len(selected_markers)\n",
    "\n",
    "sc.pp.scale(ref_py)\n",
    "sc.pp.scale(adata)\n",
    "\n",
    "ref_py.obs[cell_type] = ref_py.obs[cell_type].tolist()\n",
    "len(ref_py.obs[cell_type].unique())\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "n_feat = ref_py.shape[1]\n",
    "n_labs = len(ref_py.obs[cell_type].unique())\n",
    "\n",
    "ds = deepscore.DeepScore(hidden_nodes=[1024, 256],\n",
    "                n_features=n_feat, \n",
    "                n_labels=n_labs,\n",
    "                epochs=30,\n",
    "                batch_size=128, \n",
    "                activation=\"relu\", \n",
    "                dropout=True, \n",
    "                dropout_rate=0.1,\n",
    "                batchnorm=True, \n",
    "                lr=0.001,\n",
    "                weight_reg=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "ds.set_reference(ref_py, label_by=cell_type, test_prop=0.1)\n",
    "\n",
    "ds.train(earlystopping=True, patience=10, lr_scheduler=scheduler,)\n",
    "# ds.model.save(f'models/deepscore') # In case you want to save the DS model\n",
    "\n",
    "prob_df, adata = ds.annotate(adata, pred_key='Deepscore_HCA',Unclassified = False,return_pred_matrix=True)\n",
    "\n",
    "# SAVE the RESULTS on csv\n",
    "adata.obs[['Deepscore_HCA','Deepscore_HCA_score']].to_csv(f'csv/Deepscore_HCA_l1_{mod}_CLEAN.csv')\n",
    "\n",
    "prob_df.to_csv(f'csv/prob_matrix/Deepscore_HCA_l1_{mod}_CLEAN.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepscore)",
   "language": "python",
   "name": "deepscore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
