{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6643b9c9-3ec3-4af3-a083-c5b51c066612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 16:05:33.428592: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 16:05:33.716746: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-02 16:05:33.718152: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-02 16:05:34.752959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # CODE\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from scipy import sparse\n",
    "from matplotlib import rcParams\n",
    "rcParams['pdf.fonttype'] = 42 # enables correct plotting of text\n",
    "rcParams['figure.figsize'] = (7,7)\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 42\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "palette = {'CNT':'#1f77b4',\n",
    " 'DCT1':'#ff7f0e',\n",
    " 'DCT2':'#279e68',\n",
    " 'TL':'#279e68',\n",
    " 'DCT':'#279e68',\n",
    " 'ENDO':'#d62728',\n",
    " 'FIB':'#aa40fc',\n",
    " 'ICA':'#8c564b',\n",
    " 'ICB':'#e377c2',\n",
    " 'LEUK':'#b5bd61',\n",
    " 'MES_FIB':'#17becf',\n",
    " 'MES':'#17becf',\n",
    " 'PC':'#aec7e8',\n",
    " 'PEC':'#ffbb78',\n",
    " 'PODO':'#98df8a',\n",
    " 'PT':'#ff9896',\n",
    " 'PT_VCAM1':'#c5b0d5',\n",
    " 'TAL':'#c49c94',\n",
    " 'Unclassified':'#808080',\n",
    " 'Unknown':'#000000',\n",
    " 'Low_Quality_RNA':'#808080'}\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "import sys \n",
    "from deepscore import deepscore\n",
    "from deepscore import marker_analysis\n",
    "import pickle\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "cell_type = 'subclass.l3'\n",
    "\n",
    "\n",
    "# # FINE GRAINED LABEL TRANSFER PER COMPARTMENT\n",
    "\n",
    "# ## Preprocessing\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "ref_py = sc.read('/home/macera/Documentos/CZI/MANUSCRIPT_PREP/HORIZONTAL_RNA/objects/local.h5ad')  # LOAD the HCA Atlas\n",
    "ref_py = ref_py.raw.to_adata()\n",
    "ref_py.layers['counts'] = ref_py.X.copy()\n",
    "\n",
    "ref_py.var['ENSG'] = ref_py.var.index.copy()\n",
    "ref_py.var.index = ref_py.var['feature_name'].copy()\n",
    "\n",
    "cortex_celltypes_l1= ['DCT',\n",
    " 'PEC',\n",
    " 'CNT',\n",
    " 'POD',\n",
    " 'PT',\n",
    " 'IC',\n",
    " 'IMM',\n",
    " 'NEU',\n",
    " 'VSM/P',\n",
    " 'TAL',\n",
    " 'EC',\n",
    " 'FIB',\n",
    " 'PC']\n",
    "\n",
    "cortex_celltypes_l3= ['DCT1',\n",
    " 'DCT2',\n",
    " 'IC-B',\n",
    " 'B',\n",
    " 'MD',\n",
    " 'CNT-IC-A',\n",
    " 'MC',\n",
    " 'CNT',\n",
    " 'PT-S1/2',\n",
    " 'CCD-IC-A',\n",
    " 'PEC',\n",
    " 'pDC',\n",
    " 'EC-GC',\n",
    " 'POD',\n",
    " 'VSMC',\n",
    " 'aPT',\n",
    " 'CNT-PC',\n",
    " 'FIB',\n",
    " 'cDC',\n",
    " 'REN',\n",
    " 'EC-PTC',\n",
    " 'T',\n",
    " 'PT-S3',\n",
    " 'ncMON',\n",
    " 'NKC/T',\n",
    " 'aTAL1',\n",
    " 'C-TAL',\n",
    " 'PL',\n",
    " 'CCD-PC',\n",
    " 'SC/NEU',\n",
    " 'EC-LYM',\n",
    " 'MDC',\n",
    " 'N',\n",
    " 'MAST',\n",
    " 'aTAL2',\n",
    " 'aFIB',\n",
    " 'MYOF',\n",
    " 'MAC-M2',\n",
    " 'EC-AEA',\n",
    " 'VSMC/P']\n",
    "\n",
    "\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['subclass.l1'].isin(cortex_celltypes_l1)]\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['subclass.l3'].isin(cortex_celltypes_l3)]\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['condition.long'].isin(['Normal Reference'])]\n",
    "\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['state.l2'].isin(['reference','adaptive - epi','adaptive - str'])].copy()\n",
    "\n",
    "\n",
    "compute = False\n",
    "cell_type = 'subclass.l3'\n",
    "\n",
    "# for i in ref_py.obs['subclass.l1'].unique().tolist():\n",
    "#     a = i.replace('/','_')\n",
    "#     # if os.path.exists(f'objects/reference_subset/{a}.h5ad') == False:\n",
    "#     ref_py[ref_py.obs['subclass.l1'].isin([i])].write(f'objects/reference_subset_clean/{a}.h5ad', compression='gzip')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec08d871-466e-4c96-861f-ce4a268986ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 42\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7964ecb7-5931-4b20-b7a0-b214ef3f1b12",
   "metadata": {
    "tags": []
   },
   "source": [
    "cell_type_list = ref_py.obs['subclass.l1'].unique().tolist()\n",
    "single_cat_ct=[]\n",
    "for i in ref_py.obs['subclass.l1'].unique().tolist():\n",
    "    a = i.replace('/','_')\n",
    "    ref_py = sc.read(f'objects/reference_subset_clean/{a}.h5ad')\n",
    "\n",
    "    if len(ref_py.obs['subclass.l3'].unique().tolist()) == 1:\n",
    "        print(a, 'Single category')\n",
    "        single_cat_ct.append(i)\n",
    "\n",
    "for i in single_cat_ct:\n",
    "    cell_type_list.remove(i)\n",
    "single_cat_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e8887c-b3f6-4fff-b951-5f2deaf77db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_list = ['IMM', 'DCT', 'PT', 'CNT', 'TAL', 'IC', 'EC', 'FIB', 'VSM/P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab1b11-3930-4720-845b-21e8573f0dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "if compute:\n",
    "    for i in cell_type_list:\n",
    "        a = i.replace('/','_')\n",
    "        ref_py = sc.read(f'objects/reference_subset_clean/{a}.h5ad')\n",
    "\n",
    "        markers_filename= f'HCA_{a}_l3'\n",
    "        print(a)\n",
    "\n",
    "        sc.pp.normalize_total(ref_py, target_sum=1e4)\n",
    "        sc.pp.log1p(ref_py)\n",
    "    # Identify differentially expressed genes between cell types\n",
    "        sc.tl.rank_genes_groups(ref_py, cell_type, method='wilcoxon', use_raw=False)\n",
    "        ranked_genes_populations = ref_py.uns['rank_genes_groups'].copy()\n",
    "        with open(f'markers_ds/{markers_filename}.pickle', 'wb') as handle:\n",
    "            pickle.dump(ranked_genes_populations, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710681f2-04e4-4805-8eee-7b8eb5cf6d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAL\n",
      "IMM\n",
      "EC\n",
      "PT\n",
      "IC\n",
      "CNT\n",
      "PC\n",
      "DCT\n",
      "PEC\n",
      "VSM/P\n",
      "POD\n",
      "FIB\n",
      "NEU\n"
     ]
    }
   ],
   "source": [
    "mod = 'RECK'\n",
    "\n",
    "adata = sc.read(f'/home/macera/Documentos/CZI/MANUSCRIPT_PREP/REVIEWS/external_data/reck/rna_ready.h5ad', compression='gzip')\n",
    "# adata.X = adata.layers['counts'].copy()\n",
    "# adata = adata[adata.obs['batch'].isin([mod])].copy()\n",
    "ds_hca = pd.read_csv(f'csv/Deepscore_HCA_l1_{mod}_CLEAN.csv', index_col=0)\n",
    "adata.obs['Deepscore_HCA_l1'] = ds_hca['Deepscore_HCA'].astype('category')\n",
    "adata.obs['Deepscore_HCA_l1_score'] = ds_hca['Deepscore_HCA_score'].astype('category')\n",
    "\n",
    "# In[33]:\n",
    "try:\n",
    "    os.mkdir(f'objects/{mod}_subset/')\n",
    "except:\n",
    "    print('Directory for subset saving already exists')\n",
    "\n",
    "\n",
    "for i in adata.obs['Deepscore_HCA_l1'].unique():\n",
    "    print(i)\n",
    "    a = i.replace('/','_')\n",
    "    # if os.path.exists(f'objects/reference_subset/{a}.h5ad') == False:\n",
    "    adata[adata.obs['Deepscore_HCA_l1'].isin([i])].write(f'objects/{mod}_subset/{a}.h5ad', compression='gzip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75717ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMM', 'DCT', 'PT', 'CNT', 'TAL', 'IC', 'EC', 'FIB', 'VSM/P']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82757764-83d3-4912-a5e4-464ba49eec5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (Batch  (None, 1779)              7116      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               911360    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " output (Dense)              (None, 11)                2827      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1055703 (4.03 MB)\n",
      "Trainable params: 1050609 (4.01 MB)\n",
      "Non-trainable params: 5094 (19.90 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "37/37 [==============================] - 2s 17ms/step - loss: 1.0960 - categorical_accuracy: 0.6699 - val_loss: 0.5106 - val_categorical_accuracy: 0.8772 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.3456 - categorical_accuracy: 0.8934 - val_loss: 0.3662 - val_categorical_accuracy: 0.9079 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "37/37 [==============================] - 0s 14ms/step - loss: 0.1992 - categorical_accuracy: 0.9395 - val_loss: 0.3582 - val_categorical_accuracy: 0.8944 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.1331 - categorical_accuracy: 0.9635 - val_loss: 0.3276 - val_categorical_accuracy: 0.8983 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0983 - categorical_accuracy: 0.9699 - val_loss: 0.3477 - val_categorical_accuracy: 0.8868 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0696 - categorical_accuracy: 0.9814 - val_loss: 0.3393 - val_categorical_accuracy: 0.8868 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0471 - categorical_accuracy: 0.9870 - val_loss: 0.3758 - val_categorical_accuracy: 0.8829 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0395 - categorical_accuracy: 0.9883 - val_loss: 0.3801 - val_categorical_accuracy: 0.8772 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0344 - categorical_accuracy: 0.9891 - val_loss: 0.3842 - val_categorical_accuracy: 0.8887 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0283 - categorical_accuracy: 0.9938 - val_loss: 0.4039 - val_categorical_accuracy: 0.8772 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "37/37 [==============================] - 1s 14ms/step - loss: 0.0242 - categorical_accuracy: 0.9951 - val_loss: 0.4435 - val_categorical_accuracy: 0.8868 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0196 - categorical_accuracy: 0.9949 - val_loss: 0.4244 - val_categorical_accuracy: 0.8848 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0134 - categorical_accuracy: 0.9957 - val_loss: 0.4119 - val_categorical_accuracy: 0.8887 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "37/37 [==============================] - 0s 13ms/step - loss: 0.0124 - categorical_accuracy: 0.9977 - val_loss: 0.4279 - val_categorical_accuracy: 0.8829 - lr: 6.7032e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4608 - categorical_accuracy: 0.8860\n",
      "\n",
      "test loss: 0.46081, test accuracy:'               '0.88601\n",
      "135/135 [==============================] - 0s 3ms/step\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_3 (Bat  (None, 600)               2400      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               307712    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 445026 (1.70 MB)\n",
      "Trainable params: 442290 (1.69 MB)\n",
      "Non-trainable params: 2736 (10.69 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "25/25 [==============================] - 1s 12ms/step - loss: 0.7000 - categorical_accuracy: 0.7034 - val_loss: 0.5043 - val_categorical_accuracy: 0.8074 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.3868 - categorical_accuracy: 0.8681 - val_loss: 0.3493 - val_categorical_accuracy: 0.8895 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.2652 - categorical_accuracy: 0.9293 - val_loss: 0.2404 - val_categorical_accuracy: 0.9292 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1912 - categorical_accuracy: 0.9501 - val_loss: 0.2117 - val_categorical_accuracy: 0.9547 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1545 - categorical_accuracy: 0.9621 - val_loss: 0.1191 - val_categorical_accuracy: 0.9717 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1235 - categorical_accuracy: 0.9691 - val_loss: 0.0841 - val_categorical_accuracy: 0.9773 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1041 - categorical_accuracy: 0.9684 - val_loss: 0.0992 - val_categorical_accuracy: 0.9745 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0888 - categorical_accuracy: 0.9770 - val_loss: 0.0803 - val_categorical_accuracy: 0.9745 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0776 - categorical_accuracy: 0.9776 - val_loss: 0.0832 - val_categorical_accuracy: 0.9745 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0732 - categorical_accuracy: 0.9782 - val_loss: 0.0708 - val_categorical_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0639 - categorical_accuracy: 0.9830 - val_loss: 0.0897 - val_categorical_accuracy: 0.9688 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0723 - categorical_accuracy: 0.9782 - val_loss: 0.1615 - val_categorical_accuracy: 0.9688 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0546 - categorical_accuracy: 0.9855 - val_loss: 0.0702 - val_categorical_accuracy: 0.9773 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0560 - categorical_accuracy: 0.9814 - val_loss: 0.0731 - val_categorical_accuracy: 0.9773 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0458 - categorical_accuracy: 0.9864 - val_loss: 0.0657 - val_categorical_accuracy: 0.9773 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0565 - categorical_accuracy: 0.9855 - val_loss: 0.0671 - val_categorical_accuracy: 0.9773 - lr: 5.4881e-04\n",
      "Epoch 17/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0294 - categorical_accuracy: 0.9924 - val_loss: 0.0695 - val_categorical_accuracy: 0.9773 - lr: 4.9659e-04\n",
      "Epoch 18/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0420 - categorical_accuracy: 0.9880 - val_loss: 0.0797 - val_categorical_accuracy: 0.9717 - lr: 4.4933e-04\n",
      "Epoch 19/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0399 - categorical_accuracy: 0.9893 - val_loss: 0.0757 - val_categorical_accuracy: 0.9745 - lr: 4.0657e-04\n",
      "Epoch 20/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0326 - categorical_accuracy: 0.9918 - val_loss: 0.0791 - val_categorical_accuracy: 0.9745 - lr: 3.6788e-04\n",
      "Epoch 21/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0279 - categorical_accuracy: 0.9912 - val_loss: 0.0784 - val_categorical_accuracy: 0.9802 - lr: 3.3287e-04\n",
      "Epoch 22/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0398 - categorical_accuracy: 0.9877 - val_loss: 0.0966 - val_categorical_accuracy: 0.9717 - lr: 3.0119e-04\n",
      "Epoch 23/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0334 - categorical_accuracy: 0.9890 - val_loss: 0.0731 - val_categorical_accuracy: 0.9802 - lr: 2.7253e-04\n",
      "Epoch 24/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0261 - categorical_accuracy: 0.9908 - val_loss: 0.0766 - val_categorical_accuracy: 0.9717 - lr: 2.4660e-04\n",
      "Epoch 25/30\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0171 - categorical_accuracy: 0.9950 - val_loss: 0.0743 - val_categorical_accuracy: 0.9802 - lr: 2.2313e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2059 - categorical_accuracy: 0.9566\n",
      "\n",
      "test loss: 0.20587, test accuracy:'               '0.95663\n",
      "22/22 [==============================] - 0s 2ms/step\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_6 (Bat  (None, 900)               3600      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               461312    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600083 (2.29 MB)\n",
      "Trainable params: 596747 (2.28 MB)\n",
      "Non-trainable params: 3336 (13.03 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "105/105 [==============================] - 2s 9ms/step - loss: 0.3199 - categorical_accuracy: 0.8845 - val_loss: 0.2233 - val_categorical_accuracy: 0.9302 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1969 - categorical_accuracy: 0.9257 - val_loss: 0.1597 - val_categorical_accuracy: 0.9450 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1578 - categorical_accuracy: 0.9414 - val_loss: 0.1595 - val_categorical_accuracy: 0.9436 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1419 - categorical_accuracy: 0.9467 - val_loss: 0.1691 - val_categorical_accuracy: 0.9336 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1265 - categorical_accuracy: 0.9507 - val_loss: 0.1730 - val_categorical_accuracy: 0.9336 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1127 - categorical_accuracy: 0.9581 - val_loss: 0.1837 - val_categorical_accuracy: 0.9342 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.1098 - categorical_accuracy: 0.9593 - val_loss: 0.1507 - val_categorical_accuracy: 0.9409 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0956 - categorical_accuracy: 0.9634 - val_loss: 0.1921 - val_categorical_accuracy: 0.9349 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0889 - categorical_accuracy: 0.9662 - val_loss: 0.1588 - val_categorical_accuracy: 0.9396 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0745 - categorical_accuracy: 0.9714 - val_loss: 0.1693 - val_categorical_accuracy: 0.9423 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0665 - categorical_accuracy: 0.9755 - val_loss: 0.1763 - val_categorical_accuracy: 0.9389 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0634 - categorical_accuracy: 0.9767 - val_loss: 0.1702 - val_categorical_accuracy: 0.9362 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0593 - categorical_accuracy: 0.9786 - val_loss: 0.1766 - val_categorical_accuracy: 0.9389 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0455 - categorical_accuracy: 0.9846 - val_loss: 0.2022 - val_categorical_accuracy: 0.9356 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0429 - categorical_accuracy: 0.9845 - val_loss: 0.1800 - val_categorical_accuracy: 0.9383 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0369 - categorical_accuracy: 0.9860 - val_loss: 0.1765 - val_categorical_accuracy: 0.9416 - lr: 5.4881e-04\n",
      "Epoch 17/30\n",
      "105/105 [==============================] - 1s 8ms/step - loss: 0.0303 - categorical_accuracy: 0.9893 - val_loss: 0.2134 - val_categorical_accuracy: 0.9329 - lr: 4.9659e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.2674 - categorical_accuracy: 0.9136\n",
      "\n",
      "test loss: 0.26738, test accuracy:'               '0.9136\n",
      "59/59 [==============================] - 0s 2ms/step\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_9 (Bat  (None, 600)               2400      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               307712    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 445026 (1.70 MB)\n",
      "Trainable params: 442290 (1.69 MB)\n",
      "Non-trainable params: 2736 (10.69 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "33/33 [==============================] - 1s 10ms/step - loss: 0.5007 - categorical_accuracy: 0.7761 - val_loss: 0.3068 - val_categorical_accuracy: 0.8519 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.3180 - categorical_accuracy: 0.8663 - val_loss: 0.3715 - val_categorical_accuracy: 0.8475 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2802 - categorical_accuracy: 0.8804 - val_loss: 0.2600 - val_categorical_accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2269 - categorical_accuracy: 0.9061 - val_loss: 0.2399 - val_categorical_accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2193 - categorical_accuracy: 0.9076 - val_loss: 0.2929 - val_categorical_accuracy: 0.8562 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.2099 - categorical_accuracy: 0.9136 - val_loss: 0.2362 - val_categorical_accuracy: 0.8998 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.1958 - categorical_accuracy: 0.9185 - val_loss: 0.2794 - val_categorical_accuracy: 0.8845 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 0s 8ms/step - loss: 0.1879 - categorical_accuracy: 0.9231 - val_loss: 0.2608 - val_categorical_accuracy: 0.8824 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.1723 - categorical_accuracy: 0.9265 - val_loss: 0.2537 - val_categorical_accuracy: 0.8911 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.1500 - categorical_accuracy: 0.9406 - val_loss: 0.2481 - val_categorical_accuracy: 0.8954 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.1504 - categorical_accuracy: 0.9401 - val_loss: 0.2635 - val_categorical_accuracy: 0.8954 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.1324 - categorical_accuracy: 0.9481 - val_loss: 0.2446 - val_categorical_accuracy: 0.8911 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.1189 - categorical_accuracy: 0.9532 - val_loss: 0.3068 - val_categorical_accuracy: 0.8824 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.1129 - categorical_accuracy: 0.9556 - val_loss: 0.2523 - val_categorical_accuracy: 0.9063 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.1063 - categorical_accuracy: 0.9585 - val_loss: 0.2516 - val_categorical_accuracy: 0.8976 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 0s 7ms/step - loss: 0.0939 - categorical_accuracy: 0.9622 - val_loss: 0.2577 - val_categorical_accuracy: 0.9150 - lr: 5.4881e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2502 - categorical_accuracy: 0.8978\n",
      "\n",
      "test loss: 0.2502, test accuracy:'               '0.89784\n",
      "20/20 [==============================] - 0s 2ms/step\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_12 (Ba  (None, 911)               3644      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               466944    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " output (Dense)              (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 606016 (2.31 MB)\n",
      "Trainable params: 602658 (2.30 MB)\n",
      "Non-trainable params: 3358 (13.12 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "72/72 [==============================] - 2s 10ms/step - loss: 0.5031 - categorical_accuracy: 0.8393 - val_loss: 0.3193 - val_categorical_accuracy: 0.9225 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.2600 - categorical_accuracy: 0.9152 - val_loss: 0.2608 - val_categorical_accuracy: 0.9147 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.2084 - categorical_accuracy: 0.9291 - val_loss: 0.2092 - val_categorical_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.1796 - categorical_accuracy: 0.9378 - val_loss: 0.1987 - val_categorical_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.1474 - categorical_accuracy: 0.9501 - val_loss: 0.2038 - val_categorical_accuracy: 0.9392 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.1447 - categorical_accuracy: 0.9513 - val_loss: 0.2150 - val_categorical_accuracy: 0.9324 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.1186 - categorical_accuracy: 0.9564 - val_loss: 0.1982 - val_categorical_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.1139 - categorical_accuracy: 0.9596 - val_loss: 0.2192 - val_categorical_accuracy: 0.9324 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.1117 - categorical_accuracy: 0.9633 - val_loss: 0.2242 - val_categorical_accuracy: 0.9363 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.1011 - categorical_accuracy: 0.9651 - val_loss: 0.2303 - val_categorical_accuracy: 0.9284 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0830 - categorical_accuracy: 0.9696 - val_loss: 0.2322 - val_categorical_accuracy: 0.9324 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0651 - categorical_accuracy: 0.9782 - val_loss: 0.2383 - val_categorical_accuracy: 0.9343 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0558 - categorical_accuracy: 0.9803 - val_loss: 0.2421 - val_categorical_accuracy: 0.9363 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0531 - categorical_accuracy: 0.9819 - val_loss: 0.2547 - val_categorical_accuracy: 0.9275 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0474 - categorical_accuracy: 0.9840 - val_loss: 0.2920 - val_categorical_accuracy: 0.9176 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.0377 - categorical_accuracy: 0.9872 - val_loss: 0.2928 - val_categorical_accuracy: 0.9304 - lr: 5.4881e-04\n",
      "Epoch 17/30\n",
      "72/72 [==============================] - 1s 8ms/step - loss: 0.0316 - categorical_accuracy: 0.9894 - val_loss: 0.2778 - val_categorical_accuracy: 0.9333 - lr: 4.9659e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3018 - categorical_accuracy: 0.9356\n",
      "\n",
      "test loss: 0.30179, test accuracy:'               '0.93557\n",
      "80/80 [==============================] - 0s 2ms/step\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_15 (Ba  (None, 900)               3600      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               461312    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600083 (2.29 MB)\n",
      "Trainable params: 596747 (2.28 MB)\n",
      "Non-trainable params: 3336 (13.03 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "30/30 [==============================] - 1s 12ms/step - loss: 0.3595 - categorical_accuracy: 0.8685 - val_loss: 0.6330 - val_categorical_accuracy: 0.8197 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0978 - categorical_accuracy: 0.9703 - val_loss: 0.1139 - val_categorical_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0633 - categorical_accuracy: 0.9792 - val_loss: 0.1617 - val_categorical_accuracy: 0.9391 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0461 - categorical_accuracy: 0.9862 - val_loss: 0.1591 - val_categorical_accuracy: 0.9368 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0311 - categorical_accuracy: 0.9901 - val_loss: 0.0485 - val_categorical_accuracy: 0.9883 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0306 - categorical_accuracy: 0.9901 - val_loss: 0.0436 - val_categorical_accuracy: 0.9930 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0176 - categorical_accuracy: 0.9956 - val_loss: 0.0431 - val_categorical_accuracy: 0.9930 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0150 - categorical_accuracy: 0.9945 - val_loss: 0.0346 - val_categorical_accuracy: 0.9930 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0149 - categorical_accuracy: 0.9956 - val_loss: 0.0409 - val_categorical_accuracy: 0.9930 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0147 - categorical_accuracy: 0.9956 - val_loss: 0.1032 - val_categorical_accuracy: 0.9742 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0151 - categorical_accuracy: 0.9945 - val_loss: 0.0393 - val_categorical_accuracy: 0.9930 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0140 - categorical_accuracy: 0.9951 - val_loss: 0.0374 - val_categorical_accuracy: 0.9906 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0141 - categorical_accuracy: 0.9951 - val_loss: 0.0569 - val_categorical_accuracy: 0.9883 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0117 - categorical_accuracy: 0.9953 - val_loss: 0.0567 - val_categorical_accuracy: 0.9836 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0081 - categorical_accuracy: 0.9987 - val_loss: 0.0739 - val_categorical_accuracy: 0.9836 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0078 - categorical_accuracy: 0.9971 - val_loss: 0.0599 - val_categorical_accuracy: 0.9836 - lr: 5.4881e-04\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0051 - categorical_accuracy: 0.9992 - val_loss: 0.0459 - val_categorical_accuracy: 0.9906 - lr: 4.9659e-04\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0096 - categorical_accuracy: 0.9971 - val_loss: 0.0661 - val_categorical_accuracy: 0.9789 - lr: 4.4933e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1326 - categorical_accuracy: 0.9558\n",
      "\n",
      "test loss: 0.13262, test accuracy:'               '0.95579\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_18 (Ba  (None, 1180)              4720      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               604672    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " output (Dense)              (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 744820 (2.84 MB)\n",
      "Trainable params: 740924 (2.83 MB)\n",
      "Non-trainable params: 3896 (15.22 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "43/43 [==============================] - 1s 13ms/step - loss: 0.4146 - categorical_accuracy: 0.8663 - val_loss: 0.1758 - val_categorical_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0929 - categorical_accuracy: 0.9717 - val_loss: 0.1163 - val_categorical_accuracy: 0.9700 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0554 - categorical_accuracy: 0.9845 - val_loss: 0.0668 - val_categorical_accuracy: 0.9850 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0376 - categorical_accuracy: 0.9902 - val_loss: 0.0875 - val_categorical_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0364 - categorical_accuracy: 0.9889 - val_loss: 0.0738 - val_categorical_accuracy: 0.9834 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0247 - categorical_accuracy: 0.9920 - val_loss: 0.0775 - val_categorical_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0167 - categorical_accuracy: 0.9946 - val_loss: 0.0635 - val_categorical_accuracy: 0.9834 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0273 - categorical_accuracy: 0.9924 - val_loss: 0.0690 - val_categorical_accuracy: 0.9834 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0243 - categorical_accuracy: 0.9919 - val_loss: 0.0870 - val_categorical_accuracy: 0.9767 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0151 - categorical_accuracy: 0.9956 - val_loss: 0.0687 - val_categorical_accuracy: 0.9784 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0129 - categorical_accuracy: 0.9954 - val_loss: 0.0770 - val_categorical_accuracy: 0.9834 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0140 - categorical_accuracy: 0.9961 - val_loss: 0.0841 - val_categorical_accuracy: 0.9750 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0167 - categorical_accuracy: 0.9941 - val_loss: 0.0783 - val_categorical_accuracy: 0.9867 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 9ms/step - loss: 0.0113 - categorical_accuracy: 0.9965 - val_loss: 0.0710 - val_categorical_accuracy: 0.9800 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0100 - categorical_accuracy: 0.9967 - val_loss: 0.0823 - val_categorical_accuracy: 0.9800 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0090 - categorical_accuracy: 0.9974 - val_loss: 0.0806 - val_categorical_accuracy: 0.9834 - lr: 5.4881e-04\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 0.0085 - categorical_accuracy: 0.9974 - val_loss: 0.0851 - val_categorical_accuracy: 0.9850 - lr: 4.9659e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0978 - categorical_accuracy: 0.9701\n",
      "\n",
      "test loss: 0.09777, test accuracy:'               '0.97006\n",
      "15/15 [==============================] - 0s 2ms/step\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_21 (Ba  (None, 900)               3600      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               461312    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " output (Dense)              (None, 3)                 771       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600083 (2.29 MB)\n",
      "Trainable params: 596747 (2.28 MB)\n",
      "Non-trainable params: 3336 (13.03 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "19/19 [==============================] - 1s 16ms/step - loss: 0.6301 - categorical_accuracy: 0.7669 - val_loss: 0.9786 - val_categorical_accuracy: 0.5836 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.2286 - categorical_accuracy: 0.9240 - val_loss: 0.9155 - val_categorical_accuracy: 0.6468 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1542 - categorical_accuracy: 0.9421 - val_loss: 0.6528 - val_categorical_accuracy: 0.7286 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.1057 - categorical_accuracy: 0.9607 - val_loss: 0.3165 - val_categorical_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0908 - categorical_accuracy: 0.9694 - val_loss: 0.3002 - val_categorical_accuracy: 0.8922 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0770 - categorical_accuracy: 0.9756 - val_loss: 0.2119 - val_categorical_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0526 - categorical_accuracy: 0.9835 - val_loss: 0.2252 - val_categorical_accuracy: 0.9033 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0466 - categorical_accuracy: 0.9860 - val_loss: 0.2063 - val_categorical_accuracy: 0.9331 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "19/19 [==============================] - 0s 11ms/step - loss: 0.0295 - categorical_accuracy: 0.9913 - val_loss: 0.2182 - val_categorical_accuracy: 0.9331 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0320 - categorical_accuracy: 0.9901 - val_loss: 0.2162 - val_categorical_accuracy: 0.9219 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0277 - categorical_accuracy: 0.9930 - val_loss: 0.2117 - val_categorical_accuracy: 0.9108 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0271 - categorical_accuracy: 0.9917 - val_loss: 0.2060 - val_categorical_accuracy: 0.9145 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0256 - categorical_accuracy: 0.9930 - val_loss: 0.2415 - val_categorical_accuracy: 0.9257 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0197 - categorical_accuracy: 0.9938 - val_loss: 0.2135 - val_categorical_accuracy: 0.9405 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0147 - categorical_accuracy: 0.9950 - val_loss: 0.2174 - val_categorical_accuracy: 0.9257 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0150 - categorical_accuracy: 0.9967 - val_loss: 0.2058 - val_categorical_accuracy: 0.9145 - lr: 5.4881e-04\n",
      "Epoch 17/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0126 - categorical_accuracy: 0.9967 - val_loss: 0.2096 - val_categorical_accuracy: 0.9219 - lr: 4.9659e-04\n",
      "Epoch 18/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0172 - categorical_accuracy: 0.9946 - val_loss: 0.2174 - val_categorical_accuracy: 0.9219 - lr: 4.4933e-04\n",
      "Epoch 19/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0104 - categorical_accuracy: 0.9979 - val_loss: 0.2255 - val_categorical_accuracy: 0.9219 - lr: 4.0657e-04\n",
      "Epoch 20/30\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 0.0154 - categorical_accuracy: 0.9950 - val_loss: 0.2223 - val_categorical_accuracy: 0.9257 - lr: 3.6788e-04\n",
      "Epoch 21/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0102 - categorical_accuracy: 0.9979 - val_loss: 0.2579 - val_categorical_accuracy: 0.9219 - lr: 3.3287e-04\n",
      "Epoch 22/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0097 - categorical_accuracy: 0.9971 - val_loss: 0.2286 - val_categorical_accuracy: 0.9257 - lr: 3.0119e-04\n",
      "Epoch 23/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0129 - categorical_accuracy: 0.9950 - val_loss: 0.2339 - val_categorical_accuracy: 0.9182 - lr: 2.7253e-04\n",
      "Epoch 24/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0094 - categorical_accuracy: 0.9979 - val_loss: 0.2375 - val_categorical_accuracy: 0.9219 - lr: 2.4660e-04\n",
      "Epoch 25/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0110 - categorical_accuracy: 0.9979 - val_loss: 0.2351 - val_categorical_accuracy: 0.9257 - lr: 2.2313e-04\n",
      "Epoch 26/30\n",
      "19/19 [==============================] - 0s 9ms/step - loss: 0.0117 - categorical_accuracy: 0.9959 - val_loss: 0.2351 - val_categorical_accuracy: 0.9219 - lr: 2.0190e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3445 - categorical_accuracy: 0.9097\n",
      "\n",
      "test loss: 0.3445, test accuracy:'               '0.9097\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization_24 (Ba  (None, 1191)              4764      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense512 (Dense)            (None, 512)               610304    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 512)               2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense256 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " output (Dense)              (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 750496 (2.86 MB)\n",
      "Trainable params: 746578 (2.85 MB)\n",
      "Non-trainable params: 3918 (15.30 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "15/15 [==============================] - 1s 19ms/step - loss: 0.8756 - categorical_accuracy: 0.6906 - val_loss: 1.0799 - val_categorical_accuracy: 0.5900 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.2670 - categorical_accuracy: 0.9256 - val_loss: 1.0827 - val_categorical_accuracy: 0.6750 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.2032 - categorical_accuracy: 0.9422 - val_loss: 0.9170 - val_categorical_accuracy: 0.7500 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 0.1607 - categorical_accuracy: 0.9533 - val_loss: 0.4253 - val_categorical_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 0.1235 - categorical_accuracy: 0.9567 - val_loss: 0.2810 - val_categorical_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.1084 - categorical_accuracy: 0.9667 - val_loss: 0.2630 - val_categorical_accuracy: 0.9150 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0860 - categorical_accuracy: 0.9750 - val_loss: 0.1812 - val_categorical_accuracy: 0.9400 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0705 - categorical_accuracy: 0.9783 - val_loss: 0.1413 - val_categorical_accuracy: 0.9550 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0817 - categorical_accuracy: 0.9739 - val_loss: 0.1424 - val_categorical_accuracy: 0.9650 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0721 - categorical_accuracy: 0.9761 - val_loss: 0.1383 - val_categorical_accuracy: 0.9550 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0706 - categorical_accuracy: 0.9778 - val_loss: 0.1725 - val_categorical_accuracy: 0.9200 - lr: 9.0484e-04\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0526 - categorical_accuracy: 0.9861 - val_loss: 0.1595 - val_categorical_accuracy: 0.9450 - lr: 8.1873e-04\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0820 - categorical_accuracy: 0.9772 - val_loss: 0.1299 - val_categorical_accuracy: 0.9500 - lr: 7.4082e-04\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0545 - categorical_accuracy: 0.9850 - val_loss: 0.2058 - val_categorical_accuracy: 0.9500 - lr: 6.7032e-04\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0713 - categorical_accuracy: 0.9767 - val_loss: 0.1629 - val_categorical_accuracy: 0.9450 - lr: 6.0653e-04\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0624 - categorical_accuracy: 0.9806 - val_loss: 0.1369 - val_categorical_accuracy: 0.9500 - lr: 5.4881e-04\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.0652 - categorical_accuracy: 0.9789 - val_loss: 0.1415 - val_categorical_accuracy: 0.9550 - lr: 4.9659e-04\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 0s 14ms/step - loss: 0.0411 - categorical_accuracy: 0.9867 - val_loss: 0.1772 - val_categorical_accuracy: 0.9450 - lr: 4.4933e-04\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0491 - categorical_accuracy: 0.9906 - val_loss: 0.1789 - val_categorical_accuracy: 0.9450 - lr: 4.0657e-04\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0513 - categorical_accuracy: 0.9828 - val_loss: 0.1710 - val_categorical_accuracy: 0.9450 - lr: 3.6788e-04\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0434 - categorical_accuracy: 0.9878 - val_loss: 0.1597 - val_categorical_accuracy: 0.9500 - lr: 3.3287e-04\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.0424 - categorical_accuracy: 0.9883 - val_loss: 0.1876 - val_categorical_accuracy: 0.9400 - lr: 3.0119e-04\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 0s 11ms/step - loss: 0.0451 - categorical_accuracy: 0.9828 - val_loss: 0.1764 - val_categorical_accuracy: 0.9400 - lr: 2.7253e-04\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2465 - categorical_accuracy: 0.9327\n",
      "\n",
      "test loss: 0.24654, test accuracy:'               '0.93274\n",
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_markers = 300\n",
    "cell_type = 'subclass.l3'\n",
    "\n",
    "## SET PARAMETERS\n",
    "\n",
    "# ## Train & Inference\n",
    "\n",
    "for i in cell_type_list:\n",
    "    a = i.replace('/','_')\n",
    "    if os.path.exists(f'csv/Deepscore_HCA_l3_{mod}_{a}_CLEAN.csv'):\n",
    "        print(f'{mod} {a} already exists!')\n",
    "    else:\n",
    "        ref_py = sc.read(f'/home/macera/Documentos/CZI/MANUSCRIPT_PREP/DEEPSCORE/objects/reference_subset_clean/{a}.h5ad')\n",
    "        adata = sc.read(f'objects/{mod}_subset/{a}.h5ad', compression='gzip')\n",
    "\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "\n",
    "        markers_filename = f'HCA_{a}_l3'       \n",
    "        # Identify differentially expressed genes between cell types\n",
    "\n",
    "        with open(f'markers_ds/{markers_filename}.pickle', 'rb') as handle:\n",
    "            ranked_genes_populations = pickle.load(handle) \n",
    "\n",
    "            # Step 1: Create a dictionary to store markers for each subset\n",
    "        subset_markers_dict = {}\n",
    "\n",
    "        # Step 2: Store markers for each subset\n",
    "        for subset in ref_py.obs[cell_type].unique():\n",
    "            subset_markers = ranked_genes_populations['names'][subset]\n",
    "            subset_markers = [gene for gene in subset_markers if gene in adata.var.index]\n",
    "            subset_markers_dict[subset] = set(subset_markers[:n_markers+100])\n",
    "\n",
    "        # Step 3: Identify overlapping markers\n",
    "        overlapping_markers = set()\n",
    "        for subset, markers in subset_markers_dict.items():\n",
    "            for other_subset, other_markers in subset_markers_dict.items():\n",
    "                if subset != other_subset:\n",
    "                    overlapping_markers.update(markers.intersection(other_markers))\n",
    "\n",
    "        # Step 4: Select markers for each subset, excluding overlapping markers\n",
    "        marker_dict = {}\n",
    "        for subset, markers in subset_markers_dict.items():\n",
    "            unique_markers = [marker for marker in markers if marker not in overlapping_markers]\n",
    "            marker_dict[subset] = unique_markers[:n_markers]  # Select up to 200 unique markers\n",
    "            # print(subset,len(unique_markers[:n_markers]))\n",
    "        selected_markers = [marker for subset in marker_dict for marker in marker_dict[subset]]\n",
    "\n",
    "        # print(selected_markers)\n",
    "\n",
    "        sc.pp.scale(ref_py)\n",
    "        sc.pp.scale(adata) \n",
    "\n",
    "\n",
    "        # Subset the data to the selected markers\n",
    "        ref_py = ref_py[:, list(selected_markers)].copy()\n",
    "        adata = adata[:, list(selected_markers)].copy()\n",
    "\n",
    "\n",
    "\n",
    "        ref_py.obs[cell_type] = ref_py.obs[cell_type].tolist()\n",
    "        len(ref_py.obs[cell_type].unique())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "        def scheduler(epoch, lr):\n",
    "            if epoch < 10:\n",
    "                return lr\n",
    "            else:\n",
    "                return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "        n_feat = ref_py.shape[1]\n",
    "        n_labs = len(ref_py.obs[cell_type].unique())\n",
    "\n",
    "        ds = deepscore.DeepScore(hidden_nodes=[512, 256],\n",
    "                        n_features=n_feat, \n",
    "                        n_labels=n_labs,\n",
    "                        epochs=30,\n",
    "                        batch_size=128, \n",
    "                        activation=\"relu\", \n",
    "                        dropout=True, \n",
    "                        dropout_rate=0.3,\n",
    "                        batchnorm=True, \n",
    "                        lr=0.001,\n",
    "                        weight_reg=True)\n",
    "\n",
    "\n",
    "\n",
    "        os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "        import sklearn\n",
    "\n",
    "        ds.set_reference(ref_py, label_by=cell_type, test_prop=0.1)\n",
    "\n",
    "        ds.train(earlystopping=True, patience=10, lr_scheduler=scheduler,)\n",
    "\n",
    "        prob_df, adata = ds.annotate(adata, pred_key='Deepscore_HCA',Unclassified = False,return_pred_matrix=True)\n",
    "\n",
    "\n",
    "        adata.obs[['Deepscore_HCA','Deepscore_HCA_score']].to_csv(f'csv/Deepscore_HCA_l3_{mod}_{a}_CLEAN.csv')\n",
    "\n",
    "        prob_df.to_csv(f'csv/prob_matrix/Deepscore_HCA_l3_{mod}_{a}_CLEAN.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepscore)",
   "language": "python",
   "name": "deepscore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
