{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643b9c9-3ec3-4af3-a083-c5b51c066612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " ImplicitModificationWarning:/home/marioam/miniconda3/envs/General_env/lib/python3.9/site-packages/anndata/_core/anndata.py:121: Transforming to str index.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['pdf.fonttype'] = 42 # enables correct plotting of text\n",
    "rcParams['figure.figsize'] = (7,7)\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "seed = 42\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "# Import deepscore model # Add deepscore folder to path\n",
    "from deepscore import deepscore \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b84a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LOAD the PROCESS the REFERENCE\n",
    "\n",
    "# ## Preprocessing\n",
    "\n",
    "\n",
    "cell_type = 'subclass.l1'\n",
    "\n",
    "ref_py = sc.read('../HORIZONTAL_RNA/objects/local.h5ad')  # LOAD the HCA Atlas\n",
    "ref_py = ref_py.raw.to_adata()\n",
    "ref_py.layers['counts'] = ref_py.X.copy()\n",
    "\n",
    "ref_py.var['ENSG'] = ref_py.var.index.copy()\n",
    "ref_py.var.index = ref_py.var['feature_name'].copy()\n",
    "\n",
    "# SUBSET THE ATLAS TO MATCH OUR SAMPLE BIOLOGY\n",
    "\n",
    "cortex_celltypes_l1= ['DCT',\n",
    " 'PEC',\n",
    " 'CNT',\n",
    " 'POD',\n",
    " 'PT',\n",
    " 'IC',\n",
    " 'IMM',\n",
    " 'NEU',\n",
    " 'VSM/P',\n",
    " 'TAL',\n",
    " 'EC',\n",
    " 'FIB',\n",
    " 'PC']\n",
    "\n",
    "cortex_celltypes_l3= ['DCT1',\n",
    " 'DCT2',\n",
    " 'IC-B',\n",
    " 'B',\n",
    " 'MD',\n",
    " 'CNT-IC-A',\n",
    " 'MC',\n",
    " 'CNT',\n",
    " 'PT-S1/2',\n",
    " 'CCD-IC-A',\n",
    " 'PEC',\n",
    " 'pDC',\n",
    " 'EC-GC',\n",
    " 'POD',\n",
    " 'VSMC',\n",
    " 'aPT',\n",
    " 'CNT-PC',\n",
    " 'FIB',\n",
    " 'cDC',\n",
    " 'REN',\n",
    " 'EC-PTC',\n",
    " 'T',\n",
    " 'PT-S3',\n",
    " 'ncMON',\n",
    " 'NKC/T',\n",
    " 'aTAL1',\n",
    " 'C-TAL',\n",
    " 'PL',\n",
    " 'CCD-PC',\n",
    " 'SC/NEU',\n",
    " 'EC-LYM',\n",
    " 'MDC',\n",
    " 'N',\n",
    " 'MAST',\n",
    " 'aTAL2',\n",
    " 'aFIB',\n",
    " 'MYOF',\n",
    " 'MAC-M2',\n",
    " 'EC-AEA',\n",
    " 'VSMC/P']\n",
    "\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['subclass.l1'].isin(cortex_celltypes_l1)]\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['subclass.l3'].isin(cortex_celltypes_l3)]\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['condition.long'].isin(['Normal Reference'])]\n",
    "\n",
    "\n",
    "ref_py = ref_py[ref_py.obs['state.l2'].isin(['reference','adaptive - epi','adaptive - str'])].copy()\n",
    "\n",
    "\n",
    "cell_type = 'subclass.l1'\n",
    "overlapping = False\n",
    "compute = True\n",
    "\n",
    "\n",
    "ref_py.X = ref_py.X.copy()\n",
    "sc.pp.normalize_total(ref_py, target_sum=1e4)\n",
    "sc.pp.log1p(ref_py)\n",
    "\n",
    "\n",
    "markers_filename= f'HCA_l1'\n",
    "\n",
    "# Identify HCA ATLAS differentially expressed genes between cell types \n",
    "\n",
    "if compute == True:\n",
    "    sc.tl.rank_genes_groups(ref_py, cell_type, method='wilcoxon', use_raw=False)\n",
    "    ranked_genes_populations = ref_py.uns['rank_genes_groups'].copy()\n",
    "    with open(f'markers_ds/{markers_filename}.pickle', 'wb') as handle:\n",
    "        pickle.dump(ranked_genes_populations, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(f'markers_ds/{markers_filename}.pickle', 'rb') as handle:\n",
    "        ranked_genes_populations = pickle.load(handle) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c36502a-1d96-4280-aca7-c73380a1e9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed4b46d0-4c2d-4c90-859f-d69e3c38dcd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 63638 × 33920\n",
       "    obs: 'nCount_RNA', 'nFeature_RNA', 'library', 'percent.er', 'percent.mt', 'degen.score', 'aEpi.score', 'aStr.score', 'cyc.score', 'matrisome.score', 'collagen.score', 'glycoprotein.score', 'proteoglycan.score', 'S.Score', 'G2M.Score', 'experiment', 'specimen', 'condition.long', 'condition.l1', 'condition.l2', 'donor_id', 'region.l1', 'region.l2', 'percent.cortex', 'percent.medulla', 'tissue_type', 'id', 'pagoda_k100_infomap_coembed', 'subclass.full', 'subclass.l3', 'subclass.l2', 'subclass.l1', 'state.l2', 'state', 'class', 'structure', 'disease_ontology_term_id', 'sex_ontology_term_id', 'development_stage_ontology_term_id', 'self_reported_ethnicity_ontology_term_id', 'eGFR', 'BMI', 'diabetes_history', 'hypertension', 'tissue_ontology_term_id', 'organism_ontology_term_id', 'assay_ontology_term_id', 'cell_type_ontology_term_id', 'is_primary_data', 'suspension_type', 'cell_type', 'assay', 'disease', 'organism', 'sex', 'tissue', 'self_reported_ethnicity', 'development_stage'\n",
       "    var: 'feature_name', 'feature_reference', 'feature_biotype', 'ENSG'\n",
       "    uns: 'cell_type_ontology_term_id_colors', 'schema_version', 'title', 'log1p'\n",
       "    obsm: 'X_umap'\n",
       "    layers: 'counts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82757764-83d3-4912-a5e4-464ba49eec5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scRNA already exists!\n",
      "WARNING: adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 11:48:59.300151: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-01-29 11:48:59.300194: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: IJC20724\n",
      "2024-01-29 11:48:59.300204: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: IJC20724\n",
      "2024-01-29 11:48:59.300386: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\n",
      "2024-01-29 11:48:59.300433: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 525.125.6\n",
      "2024-01-29 11:48:59.300915: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 2565)              10260     \n",
      "_________________________________________________________________\n",
      "dense1024 (Dense)            (None, 1024)              2627584   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense256 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 2,908,705\n",
      "Trainable params: 2,901,015\n",
      "Non-trainable params: 7,690\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 11:48:59.631055: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 587631240 exceeds 10% of free system memory.\n",
      "2024-01-29 11:48:59.894869: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2024-01-29 11:48:59.894896: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2024-01-29 11:48:59.916028: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2024-01-29 11:48:59.917813: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 528861960 exceeds 10% of free system memory.\n",
      "2024-01-29 11:49:00.217774: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  9/403 [..............................] - ETA: 9s - loss: 1.1736 - categorical_accuracy: 0.6736 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 11:49:01.230029: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2024-01-29 11:49:01.230051: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2024-01-29 11:49:01.249695: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2024-01-29 11:49:01.251707: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2024-01-29 11:49:01.256013: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01\n",
      "\n",
      "2024-01-29 11:49:01.257296: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01/IJC20724.trace.json.gz\n",
      "2024-01-29 11:49:01.261654: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01\n",
      "\n",
      "2024-01-29 11:49:01.261721: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01/IJC20724.memory_profile.json.gz\n",
      "2024-01-29 11:49:01.261937: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01\n",
      "Dumped tool data for xplane.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01/IJC20724.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01/IJC20724.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01/IJC20724.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01/IJC20724.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_49_01/IJC20724.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403/403 [==============================] - 9s 21ms/step - loss: 0.1763 - categorical_accuracy: 0.9474 - val_loss: 0.1187 - val_categorical_accuracy: 0.9609\n",
      "Epoch 2/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0467 - categorical_accuracy: 0.9849 - val_loss: 0.1123 - val_categorical_accuracy: 0.9644\n",
      "Epoch 3/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0270 - categorical_accuracy: 0.9908 - val_loss: 0.1628 - val_categorical_accuracy: 0.9571\n",
      "Epoch 4/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0189 - categorical_accuracy: 0.9935 - val_loss: 0.1493 - val_categorical_accuracy: 0.9604\n",
      "Epoch 5/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0181 - categorical_accuracy: 0.9941 - val_loss: 0.1595 - val_categorical_accuracy: 0.9614\n",
      "Epoch 6/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0174 - categorical_accuracy: 0.9941 - val_loss: 0.1754 - val_categorical_accuracy: 0.9548\n",
      "Epoch 7/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0145 - categorical_accuracy: 0.9951 - val_loss: 0.1765 - val_categorical_accuracy: 0.9600\n",
      "Epoch 8/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0135 - categorical_accuracy: 0.9954 - val_loss: 0.1784 - val_categorical_accuracy: 0.9590\n",
      "Epoch 9/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0172 - categorical_accuracy: 0.9940 - val_loss: 0.1747 - val_categorical_accuracy: 0.9609\n",
      "Epoch 10/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0181 - categorical_accuracy: 0.9935 - val_loss: 0.1869 - val_categorical_accuracy: 0.9604\n",
      "Epoch 11/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0142 - categorical_accuracy: 0.9950 - val_loss: 0.1814 - val_categorical_accuracy: 0.9619\n",
      "Epoch 12/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0100 - categorical_accuracy: 0.9966 - val_loss: 0.1877 - val_categorical_accuracy: 0.9619\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2080 - categorical_accuracy: 0.9580\n",
      "\n",
      "test loss: 0.20803, test accuracy:'               '0.95805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 11:50:41.081102: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 364363380 exceeds 10% of free system memory.\n",
      "2024-01-29 11:50:41.237652: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 364363380 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snRNA already exists!\n",
      "WARNING: adata.X seems to be already log-transformed.\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_3 (Batch (None, 2565)              10260     \n",
      "_________________________________________________________________\n",
      "dense1024 (Dense)            (None, 1024)              2627584   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense256 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 2,908,705\n",
      "Trainable params: 2,901,015\n",
      "Non-trainable params: 7,690\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 11:50:57.109355: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 587631240 exceeds 10% of free system memory.\n",
      "2024-01-29 11:50:57.360644: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2024-01-29 11:50:57.360663: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2024-01-29 11:50:57.360691: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/403 [..............................] - ETA: 13s - loss: 1.4632 - categorical_accuracy: 0.5911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 11:50:58.139110: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2024-01-29 11:50:58.139129: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2024-01-29 11:50:58.200394: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2024-01-29 11:50:58.201619: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2024-01-29 11:50:58.203792: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58\n",
      "\n",
      "2024-01-29 11:50:58.205042: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58/IJC20724.trace.json.gz\n",
      "2024-01-29 11:50:58.206975: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58\n",
      "\n",
      "2024-01-29 11:50:58.207039: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58/IJC20724.memory_profile.json.gz\n",
      "2024-01-29 11:50:58.207263: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58\n",
      "Dumped tool data for xplane.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58/IJC20724.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58/IJC20724.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58/IJC20724.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58/IJC20724.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_50_58/IJC20724.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403/403 [==============================] - 9s 21ms/step - loss: 0.1784 - categorical_accuracy: 0.9457 - val_loss: 0.1042 - val_categorical_accuracy: 0.9667\n",
      "Epoch 2/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0461 - categorical_accuracy: 0.9852 - val_loss: 0.1098 - val_categorical_accuracy: 0.9689\n",
      "Epoch 3/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0266 - categorical_accuracy: 0.9910 - val_loss: 0.1250 - val_categorical_accuracy: 0.9675\n",
      "Epoch 4/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0221 - categorical_accuracy: 0.9928 - val_loss: 0.1310 - val_categorical_accuracy: 0.9674\n",
      "Epoch 5/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0154 - categorical_accuracy: 0.9950 - val_loss: 0.1534 - val_categorical_accuracy: 0.9630\n",
      "Epoch 6/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0173 - categorical_accuracy: 0.9941 - val_loss: 0.1567 - val_categorical_accuracy: 0.9658\n",
      "Epoch 7/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0162 - categorical_accuracy: 0.9943 - val_loss: 0.1547 - val_categorical_accuracy: 0.9646\n",
      "Epoch 8/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0145 - categorical_accuracy: 0.9952 - val_loss: 0.1548 - val_categorical_accuracy: 0.9682\n",
      "Epoch 9/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0158 - categorical_accuracy: 0.9947 - val_loss: 0.1550 - val_categorical_accuracy: 0.9667\n",
      "Epoch 10/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0174 - categorical_accuracy: 0.9939 - val_loss: 0.1619 - val_categorical_accuracy: 0.9651\n",
      "Epoch 11/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0139 - categorical_accuracy: 0.9951 - val_loss: 0.1611 - val_categorical_accuracy: 0.9653\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2306 - categorical_accuracy: 0.9547\n",
      "\n",
      "test loss: 0.23064, test accuracy:'               '0.95475\n",
      "scRNA5p already exists!\n",
      "WARNING: adata.X seems to be already log-transformed.\n",
      "Model: \"deepscore\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_6 (Batch (None, 2565)              10260     \n",
      "_________________________________________________________________\n",
      "dense1024 (Dense)            (None, 1024)              2627584   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense256 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 2,908,705\n",
      "Trainable params: 2,901,015\n",
      "Non-trainable params: 7,690\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 11:52:36.776479: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2024-01-29 11:52:36.776500: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2024-01-29 11:52:36.776566: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  6/403 [..............................] - ETA: 12s - loss: 1.4345 - categorical_accuracy: 0.5794"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 11:52:37.544067: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2024-01-29 11:52:37.544088: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2024-01-29 11:52:37.603690: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2024-01-29 11:52:37.604771: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2024-01-29 11:52:37.606774: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37\n",
      "\n",
      "2024-01-29 11:52:37.607931: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37/IJC20724.trace.json.gz\n",
      "2024-01-29 11:52:37.609667: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37\n",
      "\n",
      "2024-01-29 11:52:37.609718: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37/IJC20724.memory_profile.json.gz\n",
      "2024-01-29 11:52:37.609929: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37\n",
      "Dumped tool data for xplane.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37/IJC20724.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37/IJC20724.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37/IJC20724.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37/IJC20724.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./deepscore_logs/train/plugins/profile/2024_01_29_11_52_37/IJC20724.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403/403 [==============================] - 9s 21ms/step - loss: 0.1793 - categorical_accuracy: 0.9455 - val_loss: 0.1158 - val_categorical_accuracy: 0.9651\n",
      "Epoch 2/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0459 - categorical_accuracy: 0.9849 - val_loss: 0.1354 - val_categorical_accuracy: 0.9619\n",
      "Epoch 3/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0250 - categorical_accuracy: 0.9916 - val_loss: 0.1431 - val_categorical_accuracy: 0.9626\n",
      "Epoch 4/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0198 - categorical_accuracy: 0.9934 - val_loss: 0.1576 - val_categorical_accuracy: 0.9605\n",
      "Epoch 5/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0186 - categorical_accuracy: 0.9938 - val_loss: 0.1937 - val_categorical_accuracy: 0.9562\n",
      "Epoch 6/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0151 - categorical_accuracy: 0.9946 - val_loss: 0.1732 - val_categorical_accuracy: 0.9625\n",
      "Epoch 7/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0125 - categorical_accuracy: 0.9958 - val_loss: 0.1888 - val_categorical_accuracy: 0.9607\n",
      "Epoch 8/30\n",
      "403/403 [==============================] - 8s 20ms/step - loss: 0.0164 - categorical_accuracy: 0.9942 - val_loss: 0.1914 - val_categorical_accuracy: 0.9602\n",
      "Epoch 9/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0159 - categorical_accuracy: 0.9945 - val_loss: 0.1886 - val_categorical_accuracy: 0.9612\n",
      "Epoch 10/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0161 - categorical_accuracy: 0.9944 - val_loss: 0.1880 - val_categorical_accuracy: 0.9621\n",
      "Epoch 11/30\n",
      "403/403 [==============================] - 8s 21ms/step - loss: 0.0147 - categorical_accuracy: 0.9949 - val_loss: 0.1849 - val_categorical_accuracy: 0.9619\n",
      "\n",
      "Evaluating model performance on unseen data (test data):\n",
      "\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2136 - categorical_accuracy: 0.9524\n",
      "\n",
      "test loss: 0.21356, test accuracy:'               '0.95239\n"
     ]
    }
   ],
   "source": [
    "## SET PARAMETERS\n",
    "n_markers = 500 # Max number of markers to use per cell-type\n",
    "overlapping = False # Parameter to control overlapping marker genes between cell types on the prediction.\n",
    "\n",
    "\n",
    "ref_py_save = ref_py.copy()\n",
    "\n",
    "for mod in ['scRNA','snRNA','scRNA5p']:\n",
    "    if os.path.exists(f'csv/Deepscore_HCA_l1_{mod}_CLEAN.csv'):\n",
    "        print(f'{mod} already exists!')\n",
    "\n",
    "    adata = sc.read(f'../HORIZONTAL_RNA/objects/{mod}_raw.h5ad', compression='gzip')\n",
    "    adata.X = adata.layers['counts'].copy()\n",
    "    adata = adata[adata.obs['batch'].isin([mod])].copy()\n",
    "\n",
    "\n",
    "    with open(f'markers_ds/{markers_filename}.pickle', 'rb') as handle:\n",
    "        ranked_genes_populations = pickle.load(handle) \n",
    "\n",
    "    if overlapping:\n",
    "        selected_markers =[]\n",
    "        for cell_type_ in ref_py.obs[cell_type].unique():\n",
    "            cell_type_markers = []\n",
    "            for marker in ranked_genes_populations['names'][cell_type_][:n_markers]:\n",
    "                if marker in adata.var.index: \n",
    "                    selected_markers.append(marker)\n",
    "        selected_markers = set(selected_markers)\n",
    "\n",
    "    else:\n",
    "        # Step 2: Store markers for each subset\n",
    "        subset_markers_dict ={}\n",
    "        for subset in ref_py.obs[cell_type].unique():\n",
    "            subset_markers = ranked_genes_populations['names'][subset]\n",
    "            subset_markers = [gene for gene in subset_markers if gene in adata.var.index]\n",
    "            subset_markers_dict[subset] = set(subset_markers[:n_markers+100])\n",
    "\n",
    "        # Step 3: Identify overlapping markers\n",
    "        overlapping_markers = set()\n",
    "        for subset, markers in subset_markers_dict.items():\n",
    "            for other_subset, other_markers in subset_markers_dict.items():\n",
    "                if subset != other_subset:\n",
    "                    overlapping_markers.update(markers.intersection(other_markers))\n",
    "\n",
    "        # Step 4: Select markers for each subset, excluding overlapping markers\n",
    "        marker_dict = {}\n",
    "        for subset, markers in subset_markers_dict.items():\n",
    "            unique_markers = [marker for marker in markers if marker not in overlapping_markers]\n",
    "            marker_dict[subset] = unique_markers[:n_markers]  # Select up to TOP n_markers\n",
    "        selected_markers = [marker for subset in marker_dict for marker in marker_dict[subset]]\n",
    "\n",
    "\n",
    "\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "\n",
    "    # Subset the data to the selected markers\n",
    "\n",
    "    ref_py = ref_py_save[:, list(selected_markers)].copy()\n",
    "    adata = adata[:, list(selected_markers)].copy()\n",
    "\n",
    "    len(selected_markers)\n",
    "\n",
    "    sc.pp.scale(ref_py)\n",
    "    sc.pp.scale(adata)\n",
    "\n",
    "    ref_py.obs[cell_type] = ref_py.obs[cell_type].tolist()\n",
    "    len(ref_py.obs[cell_type].unique())\n",
    "\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "        if epoch < 10:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-0.1)\n",
    "\n",
    "\n",
    "    n_feat = ref_py.shape[1]\n",
    "    n_labs = len(ref_py.obs[cell_type].unique())\n",
    "\n",
    "    ds = deepscore.DeepScore(hidden_nodes=[1024, 256],\n",
    "                   n_features=n_feat, \n",
    "                   n_labels=n_labs,\n",
    "                   epochs=30,\n",
    "                   batch_size=128, \n",
    "                   activation=\"relu\", \n",
    "                   dropout=True, \n",
    "                   dropout_rate=0.1,\n",
    "                   batchnorm=True, \n",
    "                   lr=0.001,\n",
    "                   weight_reg=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    import os\n",
    "    os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "\n",
    "    ds.set_reference(ref_py, label_by=cell_type, test_prop=0.1)\n",
    "\n",
    "    ds.train(earlystopping=True, patience=10, lr_scheduler=scheduler,)\n",
    "    # ds.model.save(f'models/deepscore') # In case you want to save the DS model\n",
    "\n",
    "    prob_df, adata = ds.annotate(adata, pred_key='Deepscore_HCA',Unclassified = False,return_pred_matrix=True)\n",
    "\n",
    "    # SAVE the RESULTS on csv\n",
    "    adata.obs[['Deepscore_HCA','Deepscore_HCA_score']].to_csv(f'csv/Deepscore_HCA_l1_{mod}_CLEAN.csv')\n",
    "\n",
    "    prob_df.to_csv(f'csv/prob_matrix/Deepscore_HCA_l1_{mod}_CLEAN.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "General_env",
   "language": "python",
   "name": "general_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
